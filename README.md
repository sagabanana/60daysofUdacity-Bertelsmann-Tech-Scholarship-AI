# 60daysofUdacity-Bertelsmann-Tech-Scholarship-AI
code/work through the AI in Business, Foundations course content and related to this scholarship for at least 30 mins every day

## 12/10/2020
Day 1: made the pledge to study the coursework for at least 30 mins a day for the next 60 days.
I completed Part 3. Lesson 1: Data Fit and Annotation; 1-10 


## 12/11/2020
Day 2: 1) continued data fit and annotation.  2) Finally, watched The Social Dilemma.  The most astute, simple, true statement that I heard on the subject to date:

"Algorithms is an opinion embedded in code. It's really different from what you think most people think of algorithms. They think algorithms are objective and true and scientific. That's a marketing trick. It's also a marketing trick to intimidate you with algorithms, to make you trust and fear algorithms because you trust and fear mathematics."

by Cathy O'Neil, Data Scientist who wrote "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy."

I found her TedTalk video for reference.  There she says: "I have two more messages, one for the data scientists out there. Data scientists: we should not be the arbiters of truth. We should be translators of ethical discussions that happen in larger society.

And the rest of you, the non-data scientists: this is not a math test. This is a political fight. We need to demand accountability for our algorithmic overlords."  https://www.ted.com/talks/cathy_o_neil_the_era_of_blind_faith_in_big_data_must_end?utm_campaign=tedspread&utm_medium=referral&utm_source=tedcomshare

3) Learned of Qwant.com which claims that this search engine doesn't collect data from users.  https://en.wikipedia.org/wiki/Qwant  "Qwant is a French web search engine, launched in July 2013 and operated from Paris. It is one of the few EU-based search engines with its own indexing engine. It claims that it does not employ user tracking or personalize search results in order to avoid trapping users in a filter bubble. The search engine is available in 26 languages."


## 12/12-13/2020
Day 3 & 4: Finished Data Fit and Annotation. Started Optional Project: Create a Medical Image Annotation Job.  I hope to find a peer(s) to work on this together.

## 12/14/2020
Day 5: Continued to review the Optional project: Create a Medical Image Annotation Job.

## 12/15/2020
Day 6: Reviewed the optional project and completed Lesson 4.1-5

## 12/16-18/2020
Day 7, 8 and 9: Reviewed the optional project and completed Lesson 4.6-11.  Read and shared 1) https://www.propublica.org/article/only-seven-of-stanfords-first-5-000-vaccines-were-designated-for-medical-residents 2) https://www.npr.org/2020/12/17/947413170/google-ai-team-demands-ousted-black-researcher-be-rehired-and-promoted 3) https://venturebeat.com/2020/12/16/from-whistleblower-laws-to-unions-how-googles-ai-ethics-meltdown-could-shape-policy/

## 12/19/2020
Day 10: Completed Lesson 4.11-20

Sharing Ursula K Le Guin's words:

“Success is somebody else’s failure.”

“Any human power can be resisted and changed by human beings”

“What goes too long unchanged destroys itself.”

## 12/20/2020
Day 11: started 4 Lesson 2 Optional Project:  Build a Model 

Read and shared a read about Ubuntu.  "Ubuntu, how can one of be happy if all the other ones are sad?'

Ubuntu is more commonly interpreted as ‘I am because we are’. It means that we are all a sum total not just of our own experiences but because we are social creatures, we are a collective summary of our own as well as the shared experiences of our society.

Desmond Tutu beautifully said “A person is a person through other persons. None of us comes into the world fully formed. We would not know how to think, or walk, or speak, or behave as human beings unless we learned it from other human beings. We need other human beings in order to be human”.

https://www.shradhahrd.com/blog/ubuntu-i-am-because-we-are/

## 12/21/2020
Day 12: 4 Lesson 2 optional project:  Build a Model
Launched #sg_strictly_projects study group
Read and shared 2 articles:  1) https://www.bloomberg.com/news/articles/2020-12-03/intern-builds-billion-dollar-company-inspired-by-mom-s-comment
'Tsuruoka was studying information technology in college when he started his internship at the crowdfunding startup. He recalls being fascinated by the success of companies like PayPal Holdings Inc., though he hadn’t imagined setting up a business himself.
Then, when his mom said she wanted her own online store, the idea sprang from that. He began working on the business and later quit college.
“I started Base as a hobby,” he said. “But it was well-received by everyone, so I ended up setting up a company.”'
2) https://blog.samaltman.com/how-to-be-successful Written by Sal Altman, President of Y Combinator

## 12/22/2020
Day 13:  Continued with the 2nd optional project:  Build a model
Read, shared and discussed AI: 
1) 'On Tuesday, December 15, the Air Force successfully flew an AI copilot on a U-2 spy plane in California: the first time AI has controlled a U.S. military system.'
The U.S. Air Force flew an artificial intelligence (AI) copilot on a U-2 spy plane in California.
The flight marked the first time in the history of the Department of Defense that an AI took flight aboard a military aircraft.
The AI algorithm, developed by Air Combat Command’s U-2 Federal Laboratory, trained the AI to execute specific in-flight tasks that would otherwise be done by the pilot.
https://www.popularmechanics.com/military/aviation/a34978872/artificial-intelligence-controls-u2-spy-plane-air-force-exclusive/
2) https://phys.org/news/2020-12-artificial-intelligence-schrdinger-equation.html

Thought for the day.  The words of Sam Altman, the former president of Y Combinator and now the CEO of OpenAI from 'How to be Successful'

3. Learn to think independently

Entrepreneurship is very difficult to teach because original thinking is very difficult to teach. School is not set up to teach this—in fact, it generally rewards the opposite. So you have to cultivate it on your own.

Thinking from first principles and trying to generate new ideas is fun, and finding people to exchange them with is a great way to get better at this. The next step is to find easy, fast ways to test these ideas in the real world.

“I will fail many times, and I will be really right once” is the entrepreneurs’ way. You have to give yourself a lot of chances to get lucky.

One of the most powerful lessons to learn is that you can figure out what to do in situations that seem to have no solution. The more times you do this, the more you will believe it. Grit comes from learning you can get back up after you get knocked down.

## 12/23/2020
Day 14:  Reviewed the 2nd optional project and started 5. Measuring Impact and Updating Models

## 12/24/2020
Dady 15:  Completed  5.1.2 Measuring Impact and Updating Models - 5.2.6 Case Study: Video Annotation

## 12/25/2020
Day 16:  Continued 5 Lesson 2 Case Study:  Video Annotation 
Read and shared https://www.weforum.org/agenda/2020/11/ai-automation-creativity-workforce-skill-fute-of-work

## 12/26/2020
Day 17:  Read and shared 'World order is going to be rocked by AI - this is how'
https://www.weforum.org/agenda/2020/02/ai-looks-set-to-disrupt-the-established-world-order-here-s-how

Sharing Sam Altman, the former president of Y Combinator and now the CEO of OpenAI from 'How to be Successful'

'2. Have almost too much self-belief

Self-belief is immensely powerful. The most successful people I know believe in themselves almost to the point of delusion.

Cultivate this early. As you get more data points that your judgment is good and you can consistently deliver results, trust yourself more.

If you don’t believe in yourself, it’s hard to let yourself have contrarian ideas about the future. But this is where most value gets created.

I remember when Elon Musk took me on a tour of the SpaceX factory many years ago. He talked in detail about manufacturing every part of the rocket, but the thing that sticks in memory was the look of absolute certainty on his face when he talked about sending large rockets to Mars. I left thinking “huh, so that’s the benchmark for what conviction looks like.”

Managing your own morale—and your team’s morale—is one of the greatest challenges of most endeavors. It’s almost impossible without a lot of self-belief. And unfortunately, the more ambitious you are, the more the world will try to tear you down.  

Most highly successful people have been really right about the future at least once at a time when people thought they were wrong. If not, they would have faced much more competition.

Self-belief must be balanced with self-awareness. I used to hate criticism of any sort and actively avoided it. Now I try to always listen to it with the assumption that it’s true, and then decide if I want to act on it or not. Truth-seeking is hard and often painful, but it is what separates self-belief from self-delusion.

This balance also helps you avoid coming across as entitled and out of touch.'

## 12/27/2020
Day 18: Getting ready to pair up project teams #sg_strictly_project

## 12/28/2020
Day 19:  Finished the last lesson 5, completed Bertelsman Scholarship Intro to AI in Businesss.
Set up pair project teams for #sg_strictly_project

Read https://bigthink.com/philip-perry/startup-promises-immortality-through-ai-nanotechnology-and-cloning
https://www.weforum.org/agenda/2020/09/unexpected-benefits-virtual-education
https://www.weforum.org/agenda/2020/10/ai-billion-trees-sahara-desert-technology

"When you say, “Wait a moment,” you are bound by your own karma.  When you said “Yes I will,” you are free"
-Suzuki Roshi ❤

## 12/29/2020
Day 20: 
I read one of the most read 2020 MIT Technology Review and thought about how we can stop and relieve 
the crippling damage that puts and keeps already disadvantaged people in the continuous disadvantaged loop.  
I have been alerted of this news and nothing substantial has been done to correct this flawed system. 
I think not so much that people don't care but complexity and its size of wrong is monumental to correct it all together.
We are sort of looking at each other who is going to fix the error first.  What I can do at this moment is keep talking about 
it until it gets fixed.
Here is the link:
https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/

Lastly, I am sharing the words of Henry David Thoreau and a photo of the moon from last night

I went to the woods because I wished to live deliberately, 
to front only the essential facts of life, and see if I could not learn what it had to teach, 
and not, when I came to die, discover that I had not lived. I did not wish to live what was not life, 
living is so dear; nor did I wish to practise resignation, unless it was quite necessary. 
I wanted to live deep and suck out all the marrow of life, to live so sturdily and 
Spartan-like as to put to rout all that was not life, to cut a broad swath and shave close, 
to drive life into a corner, and reduce it to its lowest terms.

Henry David Thoreau

Photo:  the moon from last night

## 12/30/2020
Day 21:  Read 'The post-app era: The next stage of education technology'

Key highlight:  "So far, the growth of education technology has been limited, in part, because of missing #edtech leadership at the school, district, and state level. The expertise, experience, and vision is absent–which leads to more purchasing and policies than inspiration and design."

"Education is suffering not just from a lack of edtech leadership, but a lack of frameworks and systems that ‘accept’ technology. The next stage of #edtech–and apps can be a big part of this–has to be smarter than the ‘solutions’ we’re currently settling for, or they’re not solutions at all."
https://www.teachthought.com/technology/stages-of-education-technology/

Read and shared an article on how developing AI models is adding up to a large carbon footprint and its grand cost that only a few select labs can afford to do it, and these a few will eventually decide the future of AI:  "All of this means that developing advanced AI models is adding up to a large carbon footprint. Unless we switch to 100% renewable energy sources, AI progress may stand at odds with the goals of cutting greenhouse emissions and slowing down climate change. The financial cost of development is also becoming so high that only a few select labs can afford to do it, and they will be the ones to set the agenda for what kinds of AI models get developed."

"Looking forward, the AI community should invest more in developing energy-efficient training schemes. Otherwise, it risks having AI become dominated by a select few who can afford to set the agenda, including what kinds of models are developed, what kinds of data are used to train them and what the models are used for."

https://theconversation.com/it-takes-a-lot-of-energy-for-machines-to-learn-heres-why-ai-is-so-power-hungry-151825

# 12/31/2020

Day 22:  The last day of 2020, continuing with AI in Business. This is not directly related to AI, but a story of opportunity, decision making, dedication, preparedness, product/product management, taking risks, visionary; Dr. Sahin and follow-ups; his wife Dr. Türeci partnership and entrepreneurship. How this (scientist) couple from Turkey immigrated to Germany taking a chance, opportunity to make a better life for themselves and others and developed the record-setting Covid vaccine in just a few hours over a single day.  Normally it takes about 5 to 15 years.  They have been working on a vaccine to cure cancer for last 20 years and try the same idea to develop the Covid vaccine partnership with Pfizer.   It's always interesting to see how one thing leads to another, "Life is what happens to you while you're busy making other plans."  Here is the WSJ interview's audio recording with the creator of the record-setting Covid vaccine, Dr. Sahin. https://www.wsj.com/articles/how-a-couples-quest-to-cure-cancer-led-to-the-wests-first-covid-19-vaccine-11606905001
(Dr. Sahin says "I'm confident that...we could have a normal winter next year") https://www.bbc.com/news/health-54949799
Happy last day of 2020 and New Year!!:tada: :tada: :tada: :sparkles: :sparkles: :sparkles:

## 1/1/2020
Day 23: Created more teams and added #sg_strictly_projects pair project teams in a doc and added the link of that doc to the Channel Topic to preserve the info for a longer time - thanks @Palak.Udacity's suggestion.
Went over Lesson 2: Intro to AI and ML in Business 

I listened to a sage, a Zen monk talk at Google.  Wrote and shared this gem talk to multiple channels, "Examine your life. Examine your motivation.  Take some time to listen to his talk."

https://youtu.be/_ZSHNAiQomc

## 1/2/2021
Day 24: Working on #sg_strictly_projects team building and meetings
Just read a research article on How Autism and Invention Are Connected; autism or extreme hyper-systemizing - some of the genes associated with hyper-systemizing are the same genes that code for autism.

One study called, "Silicon Valley study" has found higher number of autism or hyper-systemizing - more than twice as high in the Silicon Valley of Netherlands compared with 2 other Dutch cities.  Which gives us solid insights self explains the unethical, insensitive, inhumane phenomenas we've been witnessing and hearing, for one, the Bay area's homeless crisis is beyond out of control - which in desperate needs of empathy, diversity and inclusion, arts and humanity in the tech industry.

"The more your brain is tuned to seek such patterns, the less you can engage the brain's parallel circuit for empathy, another important and uniquely human capacity"
"Autistic people were far more likely to be on the extreme hyper-systemizing end. People working in science, technology, engineering or math (STEM) fields—bastions of invention—had a higher number of autistic traits than those not working in STEM."

https://www.wsj.com/articles/how-autism-and-invention-are-connected-11607749260

## 1/3/2021
Day 25: Had the first meeting with my pair-project team #11
Created and documented our meeting on Google doc:  https://docs.google.com/document/d/1Xiu8nSYEMUh58c0DrKxg-VMe5n5mulCpM4PREL9PjTo/edit

## 1/4/2021
Day 26: Working on Optional Project #1:  Create a Medical Image Annotation Job
Sharing a beautiful piano piece played by Glenn Gould, Concerto for Keyboard and Orchestra No. 5 in F Minor, BWV 1056: II. Largo
https://youtu.be/4f47EmgnN7Y

## 1/5/2021

Day 27: I read a lot today.  Among a number of things I read (and watched), I will share about the Turing test as the question, "Is The Turing Test Obsolete?" made me curious to understand the author's point of view recently. I will not write about my thoughts now but here is what 'Rohit Prassad, VP and head scientist of Alexa, argues that the Turing test has us barking up the wrong set of trees. He writes in Fast Company:

I believe the goal put forth by Turing is not a useful one for AI scientists like myself to work toward. The Turing Test is fraught with limitations, some of which Turing himself debated in his seminal paper. With AI now ubiquitously integrated into our phones, cars, and homes, it’s become increasingly obvious that people care much more that their interactions with machines be useful, seamless and transparent—and that the concept of machines being indistinguishable from a human is out of touch.'
(https://www.extremetech.com/computing/318767-is-the-turing-test-obsolete)

While I was reading about the Turing test, I read interesting speculation about the test from Standford Encyclopedia of Philosophy:

'The phrase “The Turing Test” is sometimes used more generally to refer to some kinds of behavioural tests for the presence of mind, or thought, or intelligence in putatively minded entities. So, for example, it is sometimes suggested that The Turing Test is prefigured in Descartes’ Discourse on the Method. (Copeland (2000:527) finds an anticipation of the test in the 1668 writings of the Cartesian de Cordemoy. Abramson (2011a) presents archival evidence that Turing was aware of Descartes’ language test at the time that he wrote his 1950 paper. Gunderson (1964) provides an early instance of those who find that Turing’s work is foreshadowed in the work of Descartes.) In the Discourse, Descartes says:

If there were machines which bore a resemblance to our bodies and imitated our actions as closely as possible for all practical purposes, we should still have two very certain means of recognizing that they were not real men. The first is that they could never use words, or put together signs, as we do in order to declare our thoughts to others. For we can certainly conceive of a machine so constructed that it utters words, and even utters words that correspond to bodily actions causing a change in its organs. … But it is not conceivable that such a machine should produce different arrangements of words so as to give an appropriately meaningful answer to whatever is said in its presence, as the dullest of men can do. Secondly, even though some machines might do some things as well as we do them, or perhaps even better, they would inevitably fail in others, which would reveal that they are acting not from understanding, but only from the disposition of their organs. For whereas reason is a universal instrument, which can be used in all kinds of situations, these organs need some particular action; hence it is for all practical purposes impossible for a machine to have enough different organs to make it act in all the contingencies of life in the way in which our reason makes us act. (Translation by Robert Stoothoff) https://plato.stanford.edu/entries/turing-test/

Lastly, to seal off the day, I didn't catch this until today. In Terminator 2, there's a scene that two robots talk to each other, both trying to convince by lying (Terminator gives T-1000 incorrect dog name intentionally to test) and questioning the other that they're human - a sure sign of the passing of the Turing test and this was done in 1991 and now 2021, ~30 years later!! After seeing this scene it's more believable than not that AI can and will eventually think, manipulate like humans and lie like in the movie.  Here is the clip, the only time that the T-1000 and T-800 actually talk to each other, they are both impersonating other people.  

https://youtu.be/MT_u9Rurrqg

To continue from @Enzo Erbano's #60daysofudacity post.  Check this out @Alexa. N. @Enzo Erbano @Joanna Pol :point_up_2: and thanks for your inspiration and support, always!!   

## 1/6/2021
Day 28: 
Read and watched the documentary about a math teacher at the center of “Miyamoto and the Machine” who believes that a well-crafted puzzle can tell a story in numbers.  The inventor of KenKen puzzle, Miyamoto was asked about his thoughts on the puzzle created by the software and he replied, “I feel nothing from this puzzle,” Miyamoto remarks when shown the fruits of the software. “Do you think that, eventually, computers will be able to make a puzzle that is more similar to your puzzles?” Chris Flaherty, one of the film’s producers, asks Miyamoto. The Kenerator would never replace him, the sensei assures us. “Impossible,” he says. “A machine doesn’t have heart.”  This statement caused me to stop and think about what's more than the often ignored developing AI, the difference between human and AI in which truly make difference.  A reminder, the kind of attitude we should have when we are working, creating software/AI for others.
https://www.newyorker.com/culture/the-new-yorker-documentary/the-puzzle-inventor-who-makes-math-beautiful

Watched a bit of Geoff Hinton speaks about his latest research and the future of AI: https://youtu.be/N0ER1MC9cqM

## 1/7/2021
Day 29:
Read and corresponded with other scholars on the Turing test; AI and Machine.  Here is the link for your review and one more: https://bertelsmannaitrack.slack.com/archives/C01HBNAA6JC/p1610076169251900?thread_ts=1609912890.102100&cid=C01HBNAA6JC
https://bertelsmannaitrack.slack.com/archives/C01HBNAA6JC/p1610076862260500?thread_ts=1609912890.102100&cid=C01HBNAA6JC

## 1/8/2021
Day 30:
Read and reply to Ai and the Turing test thread.  Worked on forming teams for #sg_strictly_projects

## 1/9/2021
Day 31:
Continued with AI correspondence.

Read about STEM gender inequality researchers and bias: On average, around 30% of the world's researchers are women.

https://www.weforum.org/agenda/2020/02/stem-gender-inequality-researchers-bias/

## 1/10/2021
Day 32: 
Corresponded with my team about the project, #sg_strictly_projects we decided to meet bi-weekly.  Working on a startup idea and will be testing it tomorrow.  

Thought of the moment:  I don't want to make a living, I want to live. 

## 1/11/2021
Day 33: Read and shared an article on Tech policy; "Big Tech’s attention economy can be reformed. Here’s how." https://www.technologyreview.com/2021/01/10/1015934/  Read some of the discussion on #60daysofudacity
Tested my team's startup idea 

## 1/12/2021
Day 34:  Continued working on a startup idea, working on creating a new team #sg_strictly_projects 

Thought of the day-night:
‘And how should we behave during this Apocalypse? We should be unusually kind to one another, certainly. But we should also stop being so serious. Jokes help a lot. And get a dog, if you don’t already have one.’
Kurt Vonnegut - The Idea Killers, 1984.

## 1/13/2021

Day 35: Reading on Andrew Ng's thoughts on how AI could support democracy.  He begins stating

'Democracy stands on several pillars, among them:

1. Citizens who are informed by truthful perspectives supported by a free press and scientific enquiry
2. Institutions that create and enforce laws to make sure that society operates according to rules
3. Free and fair elections in which each individual has a vote that counts'

And how the AI community can strengthen all three:

'As ambiguous information surfaces and is tossed into the grinder of social media, recommendation engines can drive polarization. How can we build recommenders that bring people together rather than driving them apart?

Decisions to ban polarizing entities — including President Trump — from tech platforms have appeared to be made ad hoc. Instead, they need to be based on rules that are fair and consistently applied. If companies and regulators can develop such rules — which will not be easy — AI can play a significant role in implementing them at scale.

Digital tools have been used to selectively discourage voting and to gerrymander. On the positive side, they’ve also been used to inform voters and drive turnout. We need to develop new categories of tools and muster the political will to use them o empower all voters.'

https://info.deeplearning.ai/the-batch-propagandists-lie-about-ai-language-models-grok-images-machines-triage-covid-cases-world-models-shrink?ecid=ACsprvuhFb1lmQai8VicNEWuQcCyr4UUwqMxtRPjWRJqTwcgxGy4EMBM5d4zyPS-Ot1m0Z3DVcuu&utm_campaign=The%20Batch&utm_medium=email&_hsmi=106462423&_hsenc=p2ANqtz--ria-LvRR-trqIDYa3Tm0P4NROLa2pUkRk9NW3WTH3BhdIxaeOYr1_CtvDKM3y9207aKj5U_V4w5BjMvQfhFiKU9cMKg&utm_content=106462423&utm_source=hs_email

Another article, 'Google trained a trillion-parameter AI language model' saved for tomorrow:  https://venturebeat.com/2021/01/12/google-trained-a-trillion-parameter-ai-language-model/

## 1/14/2021

Day 36: Working on the optional project.  Today's reading:  1) Researchers from the Max Planck Society assessed humans' capabilities for controlling killer AI.
https://interestingengineering.com/superintelligent-ai-cannot-be-controlled-report-warns

2) "Consumer electronics have changed a lot in 20 years –  systems for managing e-waste aren't keeping up" —
Technical advances are reducing the volume of e-waste generated in the U.S.  But those smaller and lighter products are even harder to recycle.
'Government, industry and consumers all have roles to play. Progress will require designing products that are easier to repair and reuse, and persuading consumers to keep their devices longer.
We also see a need for responsive e-waste laws in place of today’s dated patchwork of state regulations. Establishing convenient, certified recycling locations can keep more electronics out of landfills. With retooled operations, recyclers can recover more valuable materials from the e-waste stream. Steps like these can help balance our reliance on electronic devices with systems that better protect human health and the environment.'  
https://theconversation.com/consumer-electronics-have-changed-a-lot-in-20-years-systems-for-managing-e-waste-arent-keeping-up-147972

3) “It’s a methodology that helps you define the value of your product to customers and crystallize what you’re building and why you’re building it,” Cast said. “It precedes any work by engineers."
https://www.geekwire.com/2021/working-backwards-customer-inside-amazons-strategy-launch-new-products/https://theconversation.com/consumer-electronics-have-changed-a-lot-in-20-years-systems-for-managing-e-waste-arent-keeping-up-147972

## 1/15/2021

Day 37:

Following from yesterday's read, 'the Max Planck Society assessed humans' capabilities for controlling killer AI' I read the actual press release from the Max Plack Institute for Human development which warns 'Endowing AI with noble goals may not prevent unintended consequences.' with the title 'Computer Scientists: We Wouldn’t Be Able to Control Superintelligent Machines New Findings From Theoretical Computer Science'

'We are fascinated by machines that can control cars, compose symphonies, or defeat people at chess, Go, or Jeopardy! While more progress is being made all the time in Artificial Intelligence (AI), some scientists and philosophers warn of the dangers of an uncontrollable superintelligent AI. Using theoretical calculations, an international team of researchers, including scientists from the Center for Humans and Machines at the Max Planck Institute for Human Development, shows that it would not be possible to control a superintelligent AI. The study was published in the Journal of Artificial Intelligence Research.'

https://www.mpib-berlin.mpg.de/computer-science-superintelligent-machines

Today's reflection: 

"When you look back at your own life, you see ... the sufferings you went through, each time you would have avoided it if you possibly could.  And yet, when you look at the depth of your character now, isn't a part of that a product of those experiences?  Weren't those experiences part of what created the depth of your inner being?"
- Ram Dass

## 1/16/2021
Day 38: 
Working on the optional project
Bias can creep in at many stages of the deep-learning process, and the standard practices in computer science aren’t designed to detect it.
https://www.technologyreview.com/2019/02/04/137602/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix

A complement to bias, diversity advocate Vernā Myers commands us to starts with moving toward — and not away from — what makes you uncomfortable. '[Vernā Myers] makes a plea to all people: Acknowledge your biases. Then move toward, not away from, the groups that make you uncomfortable.'
https://www.ted.com/talks/verna_myers_how_to_overcome_our_biases_walk_boldly_toward_them?utm_source=tedcomshare&utm_medium=social&utm_campaign=tedspread

## 1/17/2021
Day 39:

Corresponded with my team about the optional project #1, #sg_strictly_projects.  

Today's reading:  

A robot knocks on your door to deliver a freshly brewed cup of coffee, which you ordered just minutes earlier with one tap on your smartphone. This vision of the future could soon turn into reality as Japanese companies have started testing autonomous delivery robots on public streets. This comes as the need for social distancing amid the coronavirus pandemic has pushed up demand for autonomous delivery services.
https://www3.nhk.or.jp/nhkworld/en/news/backstories/1443

IBM has built a new chemistry lab called RoboRXN in the cloud. It combines AI models, a cloud computing platform, and robots to help scientists design and synthesize new molecules while working from home
https://www.technologyreview.com/2020/08/28/1007737/ibm-ai-robot-drug-making-lab-in-the-cloud/

Saving for later: The historian Yuval Noah Harari guides through the co-evolution of technology and democracy throughout human history, from paleolithic tribes to city states to kingdoms to nation states. So where do we go from here? Listen to the possibilities (~2 hr. listen)
https://www.humanetech.com/podcast/28-two-million-years-in-two-hours-a-conversation-with-yuval-noah-harari

Reflection: “Try to be better than yourself.” —William Faulkner

## 1/18/2021
Day 40:
Continued with the optional project and thanks to @Joanna Pol read https://towardsdatascience.com/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8

## 1/19/2021
Day 41: Corresponded with #sg_strictly_projects scholars and created another team.  Continue working on the optional projects

## 1/20/2021

Day 42: Today's reading:

1) Change is a key characteristic of the 21st century--a cause & effect. And change in education technology specifically can impact teaching.

https://www.teachthought.com/technology/5-ways-rapid-technology-change-impacts-education/

2) Saving it for later, 'Thinking Fast and Slow and the Third Wave of AI' with insights from Luis Lamb (Neurosymbolic AI), Danial Kahneman (Thinking Fast and Slow), and Francesca Rossi (Thinking Fast and Slow in AI, IBM) from the #aidebate2 organized by Montreal AI

https://medium.com/towards-artificial-intelligence/thinking-fast-and-slow-and-the-third-wave-of-ai-79156b5545e8#d74f

3) Ideally, technology should help us to create a more balanced, equal, and fair world, not use it to continue and advance a more inequitable, discriminatory world. If the methods are unsustainable, of course, the results unsustainable.

"If we don’t want our technology to be used to perpetuate racism, then we must make sure that we don’t conflate social problems like crime or violence or disease with black and brown people. When we do that, we risk turning those people into the problems that we deploy our technology to solve, the threat we design it to eradicate."
https://www.technologyreview.com/2020/06/03/1002589/technology-perpetuates-racism-by-design-simulmatics-charlton-mcilwain/

## 1/21/2021
Day 43: Working on the optional projects

Today's read:  
Google investigates another top AI ethicist.

'Why it matters: The probe follows the forced exit of Timnit Gebru, a prominent researcher also on the AI ethics team at Google whose ouster ignited a firestorm among Google employees.'

https://www.axios.com/scoop-google-is-investigating-the-actions-of-another-top-ai-e[…]=IwAR3SExFn2ws0dhH9Y0aaLFk_C9Vu5fL-bWSj0J3GeLQUpR1gLyZQNudYjg4

## 1/22/2021
Day 44: Continue with the optional projects

Have a great weekend!

Here's to the crazy ones.
The misfits.
The rebels.
The troublemakers.
The round pegs in the square holes.
The ones who see things differently.
They're not fond of rules.
And they have no respect for the status quo.
You can quote them, disagree with them,
glorify or vilify them.
About the only thing you can't do is ignore them.
Because they change things.
They push the human race forward.
While some may see them as the crazy ones,
we see genius.
Because the people who are crazy enough to think
they can change the world, are the ones who do.

-Think Different
(© 1997 Apple Computer, Inc.)

Apple "Think Different" (Steve Jobs narrated)
http://www.thecrazyones.it/spot-en.html

## 1/23 & 24/2021
Day 45 & 46:  Working on the optional projects
Reading:  Who's really benefitting from the AI Chatbots?  The Microsoft patent explains that the system would access images, voice data, social media posts, electronic messages and the like to "create or modify a special index in the theme of the specific person's personality."
https://www.cnet.com/news/microsoft-patent-details-tech-that-could-turn-dead-people-into-ai-chatbots/
Sharing Bernie Sander's words.  Bernie Sander is a US senator from Vermont:


## 1/25/2021
Day 47: Continue with the optional projects
AI Reading:  Hong Kong based Hanson Robotics said four models, including a humanoid robot named Sophia, would start rolling out of factories in the first half of 2021, just as researchers predict the pandemic will open new opportunities for the robotics industry
https://www.reuters.com/article/us-hongkong-robot-idUSKBN29U03X

## 1/26/2021
Day 48:  Continue with the optional projects
AI reading:  Not directly related to the field of AI but a much fundamentally deeper topic that will eventually disrupt AI and more.  Elon Musk wants to provide internet for all.  What would be the ramification of this plan and its development?
"Starlink is a low-Earth satellite constellation that aims to provide broadband internet to the remotest of places in the world. To date, SpaceX has launched around 1,000 satellites for the service and is now signing up early customers in the US, UK and Canada, as reported by Bloomberg."
https://www.indiatimes.com/technology/news/after-auto-and-space-elon-musk-aims-to-disrupt-telecom-sector-with-starlink-satellite-internet-532667.html  

## 1/27/2021
Day 49: Working on the optional projects
Sharing an insightful ML map

## 1/28/2021

Day 50: Was unable to work on the optional projects but I actively participated in AI discussions, reflections, and spent some time reading various topics.

AI reading:  I am about to share 2 separate articles that are deceptively closely related:  Google, AI, and people in between,  And two more for references.  The first one is about Google, previously, shared, replied to my post by @Teng Lei a few days ago and I ran across it again today.  It's about, as we've been hearing if we paid attention, Google having a management problem now - in other words, what it actually means that their management is lacking soft skills or how about 'people skills' or emotional intelligence, EI, human empathy - before Google can move on to anything else, in the clear direction of AI for Google's future and the second article is use and development of autonomous weapons powered by AI software, interestingly enough the US government appointed panel, led by no one but former Google Chief Executive Eric Schmidt - in fact, I have read and shared to my network, I believe sometime last year, about Eric Schmidt starting a (defense) government-funded university to train AI coder, AI school. In this article, the panel argues that 'it is a moral imperative' to develop AI weapons.  Wow!  The more efficient way to kill people and animals and destroy livelihood across the globe!

This is a difficult topic to discuss, surely, I think, first, Google and the US government are gigantic entities with superpower seemingly; we don't have much information/data from them except what we gather news like these, classified information to probe into.  Google's management skill has been supremely fantastic to the point that they themselves became their own stumbling block that they can't move forward, finally, it backfired them; thanks to their lack of people skills and consideration that Google employees from across the globe formed a union alliance now.  Google should pretend, at least, they are not robots, humans and acknowledge that their employees are human too with feelings and thoughts working for them and others with the hope they can make difference in the world.  

"In a previously unreported move, Mustafa Suleyman, co-founder of Google’s London-based artificial-intelligence arm, DeepMind, was stripped in late 2019 of most management responsibilities after complaints that he bullied staff, according to people familiar with the matter."

https://www.wsj.com/articles/artificial-intelligence-will-define-googles-future-for-now-its-a-management-challenge-11611676945?reflink=desktopwebshare_permalink

2 . "The US should not agree to ban the use or development of autonomous weapons powered by artificial intelligence (AI) software, a government-appointed panel has said in a draft report for Congress.

The panel, led by former Google chief executive Eric Schmidt, on Tuesday concluded two days of public discussion about how the world’s biggest military power should consider AI for national security and technological advancement.

Its vice-chairman, Robert Work, a former deputy secretary of defense, said autonomous weapons are expected to make fewer mistakes than humans do in battle, leading to reduced casualties or skirmishes caused by target misidentification.

“It is a moral imperative to at least pursue this hypothesis,” he said."

https://www.theguardian.com/science/2021/jan/26/us-has-moral-imperative-to-develop-ai-weapons-says-panel

Your thoughts, please.  This requires careful attention, thoughtful consideration and I thought why not share with you all who might be working in these very sectors and will have to make decisions soon or later?!  It's not an easy topic to discuss and some of you might find it boring, even disagree, so please don't feel obligated to make any comments but have these in your mind as a (future) product manager.   Who knows some of you might be working for Google or Eric Schmidt's AI school!  I am thankful our paths have crossed @Nibz.Ka @Sulin@Roseanne Robertson @Ijeoma Ndu @UlrikeS @Alexa. N. @Alberto M @Alem Getu @michaelkariuki @Anderson @Joanna Pol @Enzo Erbano @Etendra Verma @OlaDaniel @Sharang Sarda @shahzad @La Selene Dommu @Abayomi @Martina L. @Moz @Daniel Montilla @Ronny Andrade @Sebastian Rivera Podesta @shahzad @Dana Redeña @Marco_ @Frosty @Stanley Okonkwo @Michael Bennett @Teng Lei @F1li @Zahra'a HM @Jan S @Marco Nobili @Vijay Venugopal @Shrivar Singh @Evi Giannakou @Emmanuel Pinnick @Amardeep Singh 

## 1/29/21

Day 51: Working on the optional projects and corresponding with #sg_strictly_projects teams
Happy Friday and sharing Buckminster Fuller's words and Padraig O Tuama's The Facts of Life from Onbeing

So you might as well live
and you might as well love.
https://onbeing.org/poetry/the-facts-of-life/

## 1/30/2021

Day 52:  AI reading and reflection

Secretive agency uses AI, human 'forecasters' to predict the future
A U.S. government intelligence agency develops cutting-edge tech to predict future events.
https://bigthink.com/technology-innovation/secretive-agency-uses-ai-human-forecasters-to-predict-future

## 1/31/2021

Day 53:  Reviewed 5 Must-Read Books on Ethics in AI
https://chimera-swa.medium.com/5-must-read-books-on-ethics-in-ai-d4ed1225f98d

## 2/1/2021

Day 54: Working on the optional projects

AI reading:  A very interesting read from 2018 and I am wondering how it is now, 2021: 
'Dubai is at least attempting to attract firms and investors from around the world—unlike China, whose autocratic leadership has pursued AI dominance through homegrown technology while laying down hurdles for foreign entrants like Silicon Valley giants Facebook and Google. “Dubai is in an amazing position to welcome great ideas from all over the world,” says Khalfan Juma Belhoul, CEO of the Dubai Future Foundation, touting its proposed “country in residence” program that will help other nations develop new technologies. The type of government behind the initiatives “absolutely” does not matter, he says.'
'Derq co-founder Amer Abufadel states his view more bluntly. “Probably not being a democracy sometimes helps,” he says. “There’s one decision-maker who says, ‘We want to push forward,’ and everybody follows. There’s little room for debate. Once the leader says it, it needs to happen.”
That top-down approach sounds very much like a corporation, but a lack of democratic oversight can lead to corruption and cronyism. While the UAE ranks relatively high on countries that successfully resist graft—it’s No. 21 on Transparency International’s ranking of 180 nations—its model of governance may at some point turn into a hindrance.'
https://time.com/5195292/dubai-artificial-intelligence-derq-strategy/

## 2/2/2021

Day 55: Continue with the optional projects

AI reading: 

'An MIT computer scientist has found a way to increase robots' response time with a customized computer chip.
It could strengthen the connection between a robot's mind and body, allowing it to perform more 'human' tasks more effectively.
This innovative work could eventually relieve humans of risk in a range of settings, such as caring for COVID-19 patients or manipulating heavy objects.'

“Ideally we can eventually fabricate a custom motion-planning chip for every robot, allowing them to quickly compute safe and efficient motions,” he says. “I wouldn't be surprised if 20 years from now every robot had a handful of custom computer chips powering it, and this could be one of them.” Neuman adds that robomorphic computing might allow robots to relieve humans of risk in a range of settings, such as caring for covid-19 patients or manipulating heavy objects.

“This work is exciting because it shows how specialized circuit designs can be used to accelerate a core component of robot control,” says Robin Deits, a robotics engineer at Boston Dynamics who was not involved in the research. “Software performance is crucial for robotics because the real world never waits around for the robot to finish thinking.” He adds that Neuman’s advance could enable robots to think faster, “unlocking exciting behaviors that previously would be too computationally difficult.”

Neuman next plans to automate the entire system of robomorphic computing. Users will simply drag and drop their robot’s parameters, and “out the other end comes the hardware description. I think that’s the thing that’ll push it over the edge and make it really useful.”
 https://www.weforum.org/agenda/2021/01/robots-artificial-intelligence-machine-learning-algorithms-technology-science
